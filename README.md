# 🧠 AI vs Human Essay Classification

This project aims to build a machine learning model that can accurately distinguish between essays written by humans and those generated by AI.  
The dataset was sourced from Kaggle and includes a total of **1,460 samples**, of which only **6% are AI-generated** — making it an imbalanced binary classification task.

---

## 📁 Dataset Overview

- **Total samples**: 1,460  
- **Human-written essays**: 1,375  
- **AI-generated essays**: 85  
- **Text column**: `text`  
- **Target column**: `label` (`human` / `ai`)  

---

## 🎯 Goal

To predict whether a given essay was written by a **human** or generated by an **AI model**, based on both vocabulary and writing style.

---

## 📊 Project Pipeline

1. **Data Loading**  
2. **Exploratory Data Analysis (EDA)**  
3. **Text Preprocessing**  
   - Lowercasing, punctuation removal, stopword filtering  
4. **Feature Engineering**  
   - 🔤 TF-IDF Vectorization (top 5000 terms)  
   - ✍️ Style-Based Features:
     - Word count  
     - Lexical diversity  
     - Readability score  
     - Sentence length  
     - Stopword ratio  
     - Number of difficult words  
5. **Model Building**  
   - Logistic Regression with `class_weight='balanced'`  
6. **Evaluation**  
   - Classification Report  
   - Confusion Matrix  
   - Comparison of baseline vs enhanced model

---

## 🧪 Results

| Model                     | F1 (AI Class) | Accuracy |
|--------------------------|---------------|----------|
| TF-IDF only (baseline)   | 0.88          | 0.99     |
| TF-IDF + Style Features  | **1.00**      | **1.00** |

> ✅ Adding style-based features significantly improved the model’s performance on the minority class.
